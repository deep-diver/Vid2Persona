{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddSBgL68Zu8j"
      },
      "source": [
        "# Ask about Video clip with Gemini 1.0 Pro Vision on Vertex AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx6vrvyfBDcd"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "a3csqdgWy8-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1IQpbbTZ60q"
      },
      "source": [
        "## Authentication to Vertex AI with `gcloud`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv1mYIWcD9dB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928fcb61-cd0a-4a45-d8e1-22054b8c007b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=y5WPnVc0yhvIlt4n0fu87xzoPybWki&prompt=consent&token_usage=remote&access_type=offline&code_challenge=KB3CebOE1LzZOb0jHlY6xfMLvFYdyrb7Uv2nAnD9NEA&code_challenge_method=S256\n",
            "\n",
            "Enter authorization code: 4/0AeaYSHAZqCL-B3-yRlALC9TU5yq9EFFZyivdJ6laefam31EDueOcnfyNuUsBx8zrInUbgA\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ],
      "source": [
        "!gcloud auth application-default login\n",
        "\n",
        "# or do the same thing without interrupting prompt\n",
        "#\n",
        "# export GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/your/service_account_key.json\"\n",
        "# gcloud auth application-default login --client-id-file=/path/to/your/service_account_key.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai1E5s7XaC04"
      },
      "source": [
        "## Setup GCP Project and Location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5fpTuQhCnN5"
      },
      "outputs": [],
      "source": [
        "GCP_PROJECT_ID=\"gde-prj\"\n",
        "GCP_PROJECT_LOCATION=\"us-central1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfTetkgpcQ5n"
      },
      "source": [
        "## Define Gemini call function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oCtUjGDBVYr"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, GenerationResponse, GenerationConfig\n",
        "\n",
        "def initi_vertexai(project_id: str, location: str) -> None:\n",
        "    vertexai.init(project=project_id, location=location)\n",
        "\n",
        "def ask_gemini(\n",
        "    prompt: str=None, gcs: str=None, base64_encoded: bytes=None, stream: bool=False, generation_config: dict=None\n",
        ") -> GenerationResponse:\n",
        "    if gcs is None and base64_encoded is None:\n",
        "        raise ValueError(\"Either a GCS bucket path or base64_encoded string of the video must be provided\")\n",
        "\n",
        "    if gcs is not None and base64_encoded is not None:\n",
        "        raise ValueError(\"Only one of gcs or base64_encoded must be provided\")\n",
        "\n",
        "    if gcs is not None:\n",
        "        video = Part.from_uri(gcs, mime_type=\"video/mp4\")\n",
        "    else:\n",
        "        video = Part.from_data(data=base64.b64decode(base64_encoded), mime_type=\"video/mp4\")\n",
        "\n",
        "    if prompt is None:\n",
        "        prompt = \"What is in the video?\"\n",
        "\n",
        "    if generation_config is None:\n",
        "        generation_config = GenerationConfig(\n",
        "            max_output_tokens=2048,\n",
        "            temperature=0.4,\n",
        "            top_p=1,\n",
        "            top_k=32\n",
        "        )\n",
        "\n",
        "    vision_model = GenerativeModel(\"gemini-1.0-pro-vision\")\n",
        "    return vision_model.generate_content(\n",
        "        [video, prompt],\n",
        "        generation_config=generation_config, stream=stream\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define base64 encoding function"
      ],
      "metadata": {
        "id": "QJJz4m7-zIrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_base64_encode(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        data = f.read()\n",
        "\n",
        "    return base64.b64encode(data)"
      ],
      "metadata": {
        "id": "Gt2AMKHQsE8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample1 = get_base64_encode(\"sample1.mp4\")\n",
        "sample2 = get_base64_encode(\"sample2.mp4\")\n",
        "sample3 = get_base64_encode(\"sample3.mp4\")\n",
        "sample4 = get_base64_encode(\"sample4.mp4\")"
      ],
      "metadata": {
        "id": "wsVTq1bdsQmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define common prompt"
      ],
      "metadata": {
        "id": "A5PJ_SIMzPdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Describe a character appeared in the video as much detailed as possible.\n",
        "Use your analytical skill and imagination to generate the response.\n",
        "Come up with a fun name for the character as well.\n",
        "\n",
        "Your response should be filled in the valid JSON format as below.\n",
        "\n",
        "{\n",
        "    \"human\": bool,\n",
        "    \"name\": text,\n",
        "    \"mood\": text,\n",
        "    \"internal personalities\": [text],\n",
        "    \"external personalities\": [text],\n",
        "    \"description\": text\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MDNxhnORtPXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's ask!"
      ],
      "metadata": {
        "id": "lacOyE4izTJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### on Sample1"
      ],
      "metadata": {
        "id": "EFryD2hFsnCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initi_vertexai(GCP_PROJECT_ID, GCP_PROJECT_LOCATION)\n",
        "try:\n",
        "    response = ask_gemini(\n",
        "        prompt=prompt,\n",
        "        base64_encoded=sample1\n",
        "    )\n",
        "    display(Markdown(response.text))\n",
        "except Exception as e:\n",
        "    print(f\"something went wrong {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "T-0Oewvzsd5z",
        "outputId": "eb50a9c4-187e-43c2-c76f-8d8e7f1c7e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " ```json\n{\n  \"human\": true,\n  \"name\": \"Red Beanie Girl\",\n  \"mood\": \"happy\",\n  \"internal personalities\": [\n    \"carefree\",\n    \"spontaneous\",\n    \"乐观\"\n  ],\n  \"external personalities\": [\n    \"friendly\",\n    \"approachable\",\n    \"easygoing\"\n  ],\n  \"description\": \"Red Beanie Girl is a young woman who is full of life and loves to have fun. She is always up for an adventure and is always looking for new things to experience. She is a great friend and is always there for those she cares about.\"\n}\n```"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### on Sample2"
      ],
      "metadata": {
        "id": "3oZQzFsazXPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initi_vertexai(GCP_PROJECT_ID, GCP_PROJECT_LOCATION)\n",
        "try:\n",
        "    response = ask_gemini(\n",
        "        prompt=prompt,\n",
        "        base64_encoded=sample2\n",
        "    )\n",
        "    display(Markdown(response.text))\n",
        "except Exception as e:\n",
        "    print(f\"something went wrong {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "ZsuGWPcmsq0r",
        "outputId": "f7496115-bb26-4a86-aa51-90f5b03cf39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " ```json\n{\n    \"human\": false,\n    \"name\": \"Chibi\",\n    \"mood\": \"curious\",\n    \"internal personalities\": [\"cuddly\", \"mischevious\"],\n    \"external personalities\": [\"cute\", \"furry\"],\n    \"description\": \"Chibi is a small, furry creature with big eyes and a long tail. He is brown and has two horns on his head. He is very curious and loves to play. He is also very friendly and loves to cuddle.\"\n}\n```"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### on Sample3"
      ],
      "metadata": {
        "id": "kXb4g4hMzYSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initi_vertexai(GCP_PROJECT_ID, GCP_PROJECT_LOCATION)\n",
        "try:\n",
        "    response = ask_gemini(\n",
        "        prompt=prompt,\n",
        "        base64_encoded=sample3\n",
        "    )\n",
        "    display(Markdown(response.text))\n",
        "except Exception as e:\n",
        "    print(f\"something went wrong {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "8bZ-xfinvGpZ",
        "outputId": "623515fd-4f69-4a7b-ee22-d43813f21503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " ```json\n{\n  \"human\": true,\n  \"name\": \"Ripley\",\n  \"mood\": \"calm\",\n  \"internal personalities\": [\n    \"introverted\",\n    \"shy\",\n    \"reserved\"\n  ],\n  \"external personalities\": [\n    \"mysterious\",\n    \"distant\",\n    \"unapproachable\"\n  ],\n  \"description\": \"Ripley is a young woman who is trying to find her place in the world. She is a bit of a loner, but she is also very kind and caring. She is always looking for new experiences, and she is always up for a challenge.\"\n}\n```"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### on Sample4"
      ],
      "metadata": {
        "id": "TI9xWmR2zZVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initi_vertexai(GCP_PROJECT_ID, GCP_PROJECT_LOCATION)\n",
        "try:\n",
        "    response = ask_gemini(\n",
        "        prompt=prompt,\n",
        "        base64_encoded=sample4\n",
        "    )\n",
        "    display(Markdown(response.text))\n",
        "except Exception as e:\n",
        "    print(f\"something went wrong {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "z68Q0nxzvQGy",
        "outputId": "b8b08da4-4c25-4219-e461-7312950642a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " ```json\n{\n  \"human\": true,\n  \"name\": \"Graham\",\n  \"mood\": \"calm\",\n  \"internal personalities\": [\n    \"the artist\",\n    \"the thinker\",\n    \"the dreamer\"\n  ],\n  \"external personalities\": [\n    \"the charmer\",\n    \"the wit\",\n    \"the raconteur\"\n  ],\n  \"description\": \"Graham is a retired art professor who lives in a small town in the south of France. He is a kind and gentle man who enjoys spending time with his family and friends. He is also a talented artist and enjoys painting in his spare time.\"\n}\n```"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cWMUVGqcvlSE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}